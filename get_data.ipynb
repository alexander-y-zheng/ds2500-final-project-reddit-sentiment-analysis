{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df6bf7f",
   "metadata": {},
   "source": [
    "## Exprimenting with getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaffe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60f86ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Reddit...\n",
      "Connected to Reddit.\n"
     ]
    }
   ],
   "source": [
    "# configuration\n",
    "REDDIT_CLIENT_ID = \"DfeJt179IwKBJh5IKIOpYQ\"\n",
    "REDDIT_CLIENT_SECRET = \"ANZEcmLDpVf1eSzDE0hogh6DD88vIw\"\n",
    "REDDIT_USER_AGENT = \"WSB_Sentiment_Analysis_v1.0\"\n",
    "\n",
    "# connect to Reddit API\n",
    "print(\"Connecting to Reddit...\")\n",
    "reddit = praw.Reddit(\n",
    "    client_id=REDDIT_CLIENT_ID,\n",
    "    client_secret=REDDIT_CLIENT_SECRET,\n",
    "    user_agent=REDDIT_USER_AGENT\n",
    ")\n",
    "print(\"Connected to Reddit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce10469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_wsb_posts(limit=100):\n",
    "    \"\"\"\n",
    "    Collect recent posts from r/WallStreetBets\n",
    "    Returns a pandas DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"Collecting {limit} posts from r/WallStreetBets...\")\n",
    "    \n",
    "    subreddit = reddit.subreddit(\"wallstreetbets\")\n",
    "    \n",
    "    posts_data = []\n",
    "    \n",
    "    # Get recent posts\n",
    "    for post in subreddit.new(limit=limit):\n",
    "        # Combine title and body for ticker extraction\n",
    "        full_text = (post.title or \"\") + \" \" + (post.selftext or \"\")\n",
    "        \n",
    "        # Extract tickers mentioned\n",
    "        tickers = extract_tickers(full_text)\n",
    "        \n",
    "        # Only keep posts that mention at least one ticker\n",
    "        if tickers:\n",
    "            post_info = {\n",
    "                'date': datetime.fromtimestamp(post.created_utc).date(),\n",
    "                'title': post.title,\n",
    "                'score': post.score,\n",
    "                'num_comments': post.num_comments,\n",
    "                'tickers': ','.join(tickers),  # Store as comma-separated string\n",
    "                'text': full_text[:200]  # First 200 chars for reference\n",
    "            }\n",
    "            posts_data.append(post_info)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(posts_data)\n",
    "    print(f\"Collected {len(df)} posts with ticker mentions\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_tickers(text):\n",
    "    \"\"\"\n",
    "    Find all stock tickers in the format $TICKER (e.g., $AAPL, $GME)\n",
    "    Returns a list of unique tickers\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return []\n",
    "    \n",
    "    # Find all words starting with $ followed by 1-5 capital letters\n",
    "    tickers = re.findall(r'\\$([A-Z]{1,5})\\b', text)\n",
    "    \n",
    "    # Return unique tickers only\n",
    "    return list(set(tickers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec3881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts = collect_wsb_posts(limit=500)\n",
    "    \n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 posts:\")\n",
    "print(df_posts.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
